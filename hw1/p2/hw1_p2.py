# -*- coding: utf-8 -*-
"""dlcv_hw1_p2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19ayvj8SsUoZv5rTT10S2m4FB39RfqjuO
"""

from google.colab import drive
drive.mount('/content/drive')

# !gdown 1owVOM3V94bC8v2N8s7n56ciVzVbSzYtd -O hw1_data.zip
# !unzip ./hw1_data.zip
# !unzip /content/drive/MyDrive/DLCV/hw1/hw1_data.zip

# !unzip ./drive/MyDrive/DLCV/hw1/p2/dlcv_hw1_p2_BYOL.zip

import numpy as np
import torch
import os
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.modules.batchnorm import BatchNorm2d
from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.datasets import DatasetFolder, VisionDataset
from PIL import Image
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import random
import pandas as pd
import glob
import scipy.misc
import imageio
import argparse

# import sys
# sys.path.append('/kaggle/input/byol-pytorch')
# from byol_pytorch import BYOL

np.random.seed(10901041)
torch.manual_seed(10901041)
setting = "C"

train_transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomApply(transforms=[transforms.RandomHorizontalFlip()], p = 0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])
val_transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
])
class Dataset(Dataset):
    def __init__(self, path, transform, files=None):
        super(Dataset).__init__()
        self.path = path
        self.files = sorted([os.path.join(path, p) for p in os.listdir(path) if p.endswith(".jpg")])
        if files != None:
            self.files = files
        self.transform = transform

    def __len__(self):
        return len(self.files)

    def __getitem__(self, i):
        name = self.files[i]
        image = self.transform(Image.open(name))
        try:
            label = int(name.split("/")[-1].split("_")[0])
        except:
            label = -1
        return image, label

train_set = Dataset(
    path="./hw1_data/p2_data/office/train", transform = train_transform)
valid_set = Dataset(
    path="./hw1_data/p2_data/office/val", transform = val_transform)

print(len(train_set)) # Should print 3951
print(len(valid_set)) # Should print 406

train_loader = DataLoader(train_set, shuffle=True, pin_memory=True, batch_size=256)
valid_loader = DataLoader(valid_set, shuffle=True, batch_size=256)

class full_model(nn.Module):
    def __init__(self) -> None:
        super(full_model, self).__init__()
        self.backbone = models.resnet50(pretrained=False)
#         print(self.backbone)
        self.fc = nn.Sequential(
            nn.Linear(1000,512),
            nn.ReLU(),
            nn.Linear(512, 250),
            nn.ReLU(),
            nn.Linear(250, 65)
        )

    def forward(self, x):
        out = self.backbone(x)
        out = self.fc(out)
        return out

device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
state = torch.load("./dlcv_hw1_p2_BYOL/p2_BYOL_99.pt")
model = full_model().to(device)
a = model.backbone.load_state_dict(state)
print(a)
optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)
# optimizer = torch.optim.SDG(model.parameters(), lr=3e-4, weight_decay=1e-5)
# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-5, factor=0.8, mode='max', verbose=True)
cal_loss = nn.CrossEntropyLoss()

# for param in model.parameters():
#     param.requires_grad = False
# for param in model.fc.parameters():
#     param.requires_grad = True

best_acc = 0
num_epoch = 30
for epoch in range(num_epoch):
    # Train
    model.train()
    train_loss = []
    train_acc = []
    for batch in tqdm(train_loader):
        optimizer.zero_grad()
        images, labels = batch
        logits = model(images.to(device))
        labels = labels.to(device)
        loss = cal_loss(logits, labels)
        loss.backward()
        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)
        # print(grad_norm)
        optimizer.step()
        train_loss.append(loss.item())

        pred = logits.argmax(dim=-1)
        acc = (pred == labels).float().mean()
        if not torch.isnan(acc):
            train_acc.append(acc)
    t_loss = sum(train_loss) / len(train_loss)
    t_acc = sum(train_acc) / len(train_acc)
    print(f"[ Train | {epoch + 1:03d}/{num_epoch:03d} ] loss = {t_loss:.5f} | acc = {t_acc:5f}")

    #Val
    model.eval()
    val_loss = []
    val_acc = []
    for batch in tqdm(valid_loader):
        images, labels = batch

        with torch.no_grad():
            logits = model(images.to(device))
        labels = labels.to(device)
        loss = cal_loss(logits, labels)
        val_loss.append(loss.item())

        pred = logits.argmax(dim=-1)
        acc = (pred == labels).float().mean()
        if not torch.isnan(acc):
            val_acc.append(acc)
    v_loss = sum(val_loss) / len(val_loss)
    v_acc = sum(val_acc) / len(val_acc)
    print(f"[ Val | {epoch + 1:03d}/{num_epoch:03d} ] loss = {v_loss:.5f} | acc = {v_acc:5f}")

    # scheduler.step(v_acc)

    if v_acc > best_acc:
        print(f"best model: epoch {epoch}, save model")
        epoch_state = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            # 'scheduler': scheduler.state_dict(),
            'loss': loss

        }
        torch.save(epoch_state, f"p2_best_{setting}.pt")
#         torch.save(model.state_dict(), f"p2_best_{setting}.ckpt")
        best_acc = v_acc
    else:
        print(f"no improve: epoch {epoch}.")