# -*- coding: utf-8 -*-
"""dlcv_hw1_p1b.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qq3QvVdReS-JESnAXURTL0eY3jGFJ_W-
"""

!gdown 1owVOM3V94bC8v2N8s7n56ciVzVbSzYtd -O hw1_data.zip
!unzip ./hw1_data.zip

import numpy as np
import torch
import os
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.modules.batchnorm import BatchNorm2d
from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.datasets import DatasetFolder, VisionDataset
from PIL import Image
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import random
import pandas as pd
import glob
import scipy.misc
import imageio
import argparse

np.random.seed(10901041)
torch.manual_seed(10901041)

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomApply(transforms=[transforms.RandomHorizontalFlip(), transforms.RandomRotation(15)], p = 0.2),
    transforms.ToTensor(),
    ])
val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])
class Dataset(Dataset):
    def __init__(self, path, transform, files=None):
        super(Dataset).__init__()
        self.path = path
        self.files = sorted([os.path.join(path, p) for p in os.listdir(path) if p.endswith(".png")])
        if files != None:
            self.files = files
        # print(path)
        self.transform = transform

    def __len__(self):
        return len(self.files)

    def __getitem__(self, i):
        name = self.files[i]
        image = self.transform(Image.open(name))
        try:
          label = int(name.split("/")[-1].split("_")[0])
        except:
          label = -1
        return image, label

train_set = Dataset(
    path="./hw1_data/p1_data/train_50", transform = train_transform)
valid_set = Dataset(
    path="./hw1_data/p1_data/val_50", transform = val_transform)

print(len(train_set)) # Should print 22500
print(len(valid_set)) # Should print 2500

train_loader = DataLoader(train_set, shuffle=True,
                          batch_size=64)
valid_loader = DataLoader(valid_set, shuffle=True,
                          batch_size=64)

device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
model = models.resnet50(weights='DEFAULT').to(device)
# model.fc = nn.Linear(model.fc.in_features, 50).to(device)
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-4, momentum=0.9)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=5, gamma=0.85)
cal_loss = nn.CrossEntropyLoss(label_smoothing=0.1)

best_acc = 0
num_epoch = 50
for epoch in range(num_epoch):
    # Train
    model.train()
    train_loss = []
    train_acc = []
    for batch in tqdm(train_loader):
      optimizer.zero_grad()
      images, labels = batch
      logits = model(images.to(device))
      labels = labels.to(device)
      loss = cal_loss(logits, labels)
      loss.backward()
      optimizer.step()
      train_loss.append(loss.item())

      pred = logits.argmax(dim=-1)
      acc = (pred == labels).float().mean()
      if not torch.isnan(acc):
          train_acc.append(acc)
    t_loss = sum(train_loss) / len(train_loss)
    t_acc = sum(train_acc) / len(train_acc)
    print(f"[ Train | {epoch + 1:03d}/{num_epoch:03d} ] loss = {t_loss:.5f} | acc = {t_acc:5f}")

    #Val
    model.eval()
    val_loss = []
    val_acc = []
    for batch in tqdm(valid_loader):
      images, labels = batch

      with torch.no_grad():
        logits = model(images.to(device))
      labels = labels.to(device)
      loss = cal_loss(logits, labels)
      val_loss.append(loss.item())

      pred = logits.argmax(dim=-1)
      acc = (pred == labels).float().mean()
      if not torch.isnan(acc):
          val_acc.append(acc)
    v_loss = sum(val_loss) / len(val_loss)
    v_acc = sum(val_acc) / len(val_acc)
    print(f"[ Val | {epoch + 1:03d}/{num_epoch:03d} ] loss = {v_loss:.5f} | acc = {v_acc:5f}")
    scheduler.step()
    if v_acc > best_acc:
      torch.save(model.state_dict(), f"p1b_best_model.ckpt")
      print(f"best model: epoch {epoch}, save model")
      best_acc = v_acc
    else:
      print(f"no improve: epoch {epoch}.")

# torch.save(model.state_dict(), f"p1b_epoch_39.ckpt")

# from torch.nn.modules import activation
# from sklearn.decomposition import PCA
# from sklearn import manifold
# import matplotlib.pyplot as plt
# from matplotlib.cm import hsv
# from matplotlib.colors import ListedColormap
# import seaborn as sns
# import math

# activation = {}
# def get_activation(name):
#   def hook(model, input, output):
#     activation[name] = output.detach()
#   return hook

# def generate_colormap(color_num=50):
#     if color_num == 0:
#       color_num = 50

#     num_shades = 7
#     num_colors = (color_num + num_shades - 1) // num_shades * num_shades
#     linearly_distributed_nums = np.arange(num_colors) / num_colors
#     arr_by_shade_rows = linearly_distributed_nums.reshape(num_shades, num_colors // num_shades)
#     arr_by_shade_columns = arr_by_shade_rows.T

#     num_partitions = arr_by_shade_columns.shape[0]
#     nums_distributed_like_rising_saw = arr_by_shade_columns.reshape(-1)

#     initial_cm = hsv(nums_distributed_like_rising_saw)

#     lower_half = num_partitions // 2 * num_shades
#     upper_half = num_partitions - lower_half

#     for i in range(3):
#         initial_cm[0:lower_half, i] *= np.arange(0.2, 1, 0.8 / lower_half)
#         for j in range(upper_half):
#             modifier = np.ones(num_shades) - initial_cm[lower_half + j * num_shades: lower_half + (j + 1) * num_shades, i]
#             modifier = j * modifier / upper_half
#             initial_cm[lower_half + j * num_shades: lower_half + (j + 1) * num_shades, i] += modifier

#     return ListedColormap(initial_cm)



# def get_PCA(data, label, n=2, epoch=0)-> None:
#     data = data.cpu().detach().numpy().reshape(len(data), 512*4*4)
#     label = label.cpu().detach().numpy()
#     f_col = ["pixel" + str(i) for i in range(data.shape[1])]
#     df_c = pd.DataFrame(data, columns=f_col)
#     df_c.head()
#     pca_c = PCA(n_components=n)
#     principal_components_c = pca_c.fit_transform(df_c.iloc[:, :-1])

#     principal_c_df = pd.DataFrame(data = principal_components_c, columns = ["principal component 1", "principal component 2"])
#     principal_c_df["y"] = label
#     principal_c_df.head()
#     plt.figure(figsize=(8, 6))
#     sns.scatterplot(
#         x="principal component 1",
#         y="principal component 2",
#         palette=generate_colormap(),
#         data=principal_c_df,
#         hue="y",
#         legend="full",
#     )
#     plt.savefig(f"pca_{epoch}.png")

# def PCA_visualize(path, epoch):
#   model.eval()
#   model.load_state_dict(
#       torch.load(path)
#   )
#   model.cnn[-1].register_forward_hook(get_activation("layer_second_last"))

#   labels = []
#   labels = torch.empty(0).to(device)
#   features = torch.empty((0, 512, 4, 4), dtype=torch.float32).to(device)
#   for source_data, source_label in (valid_loader):
#       source_data = source_data.to(device)
#       source_label = source_label.to(device)
#       feature = model(source_data)
#       feature = activation["layer_second_last"]
#       features = torch.cat((features, feature), 0)
#       labels = torch.cat((labels, source_label), 0)
#   g_data = torch.empty(0, len(valid_set), 512, 4, 4).to(device)
#   g_data = torch.cat((g_data ,features[None, : ,:, :, :] ), dim = 0)
#   g_label = torch.empty( 0 , len(valid_set)).to(device)
#   g_label = torch.cat((g_label ,labels[None, :] ), dim = 0)
#   for i in range (len(g_data)):
#       get_PCA(g_data[i], g_label[i], epoch = epoch)

# PCA_visualize("./p1a_best_model.ckpt", 95)

# def plot_tsne(path, epoch):
#     model.eval()
#     model.load_state_dict(
#         torch.load(path)
#     )

#     model.cnn[-1].register_forward_hook(get_activation("layer_second_last"))

#     labels = []
#     features = torch.zeros((0, 512*4*4), dtype=torch.float32)
#     for source_data, source_label in tqdm(valid_loader):
#         source_data = source_data.to(device)
#         feature = model(source_data)
#         labels.extend(source_label.tolist())
#         feature = activation["layer_second_last"]
#         feature = feature.reshape(-1, 512*4*4)
#         features = torch.cat((features, feature.detach().cpu()), 0)
#     features = np.array(features)
#     labels = np.array(labels)


#     X_tsne = manifold.TSNE(
#         n_components=2, init="random", random_state=5, verbose=1
#     ).fit_transform(features)

#     x_min, x_max = X_tsne.min(0), X_tsne.max(0)
#     X_norm = (X_tsne - x_min) / (x_max - x_min)
#     cmap = generate_colormap()
#     fig, ax = plt.subplots(figsize=(8, 8))
#     num_categories = 50
#     for lab in range(num_categories):
#         indices = labels == lab
#         # print(indices)
#         ax.scatter(
#             X_norm[indices, 0],
#             X_norm[indices, 1],
#             c=np.array(cmap(lab)).reshape(1, 4),
#             label=lab,
#             alpha=0.5,
#         )
#     ax.legend(fontsize="large", markerscale=2)
#     plt.savefig(f"./tsne_{epoch}.png")

# plot_tsne("./p1a_epoch_0.ckpt", 0)
# plot_tsne("./p1a_epoch_31.ckpt", 31)
# plot_tsne("./p1a_epoch_39.ckpt", 39)
# plot_tsne("./p1a_epoch_99.ckpt", 99)