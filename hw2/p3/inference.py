# -*- coding: utf-8 -*-
"""dlcv_hw2_p3_inference

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tshJub4NgzUm6BaIeqYB_0zsLWftcTi6
"""

import numpy as np
import torch
import os
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.modules.batchnorm import BatchNorm2d
from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset
import torchvision.transforms as transforms
from PIL import Image
import random
import pandas as pd
import argparse

def get_args():
    parser = argparse.ArgumentParser(
        description="DANN svhn/usps"
    )
    parser.add_argument(
        "--input_dir", "-d", type=str, default="./", help="path to testing images"
    )
    parser.add_argument(
        "--output_dir", "-o", type=str, default="./test_pred.csv", help="output prediction"
    )
    parser.add_argument(
        "--svhn_model", "-sm", type=str, default=None, help="model of svhn"
    )
    parser.add_argument(
        "--usps_model", "-um", type=str, default=None, help="model of usps"
    )
    return parser.parse_args()

class DigitDataset(Dataset):
    def __init__(self, data_dir, split='all', transform=transforms.ToTensor()):
        self.data_dir = data_dir
        self.transform = transform
        self.split = split
        if split == 'all':
            self.image_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.png')])
            self.all_filename = sorted([f for f in os.listdir(data_dir) if f.endswith('.png')])
        else:
            label_file = os.path.join(data_dir, f'{split}.csv')
            with open(label_file, 'r') as f:
                lines = f.readlines()
                self.labels = [int(line.strip().split(',')[1]) for line in lines[1:]]
                self.imgs = [line.strip().split(',')[0] for line in lines[1:]]
                valid_image_files = [img for img in self.imgs]
                self.image_files = sorted(
                    [
                        os.path.join(data_dir, "data", x)
                        for x in os.listdir(os.path.join(data_dir, "data"))
                        if x in valid_image_files
                    ]
                )

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        image = Image.open(img_path).convert('RGB')  # in case there are grayscale images
        if self.transform:
            image = self.transform(image)
        return image, img_path
    def get_all_files(self):
        return self.all_filename

from torch.autograd import Function

class ReverseLayerF(Function):
    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha

        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        output = grad_output.neg() * ctx.alpha

        return output, None

class DANN(nn.Module):
    def __init__(self):
        super(DANN, self).__init__()
        self.feature = nn.Sequential()
        self.feature.add_module('f_conv1', nn.Conv2d(3, 64, kernel_size=5))
        self.feature.add_module('f_bn1', nn.BatchNorm2d(64))
        self.feature.add_module('f_pool1', nn.MaxPool2d(2))
        self.feature.add_module('f_relu1', nn.ReLU(True))
        self.feature.add_module('f_conv2', nn.Conv2d(64, 50, kernel_size=5))
        self.feature.add_module('f_bn2', nn.BatchNorm2d(50))
        self.feature.add_module('f_drop1', nn.Dropout())
        self.feature.add_module('f_pool2', nn.MaxPool2d(2))
        self.feature.add_module('f_relu2', nn.ReLU(True))

        self.class_classifier = nn.Sequential()
        self.class_classifier.add_module('c_fc1', nn.Linear(50 * 4 * 4, 100))
        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(100))
        self.class_classifier.add_module('c_relu1', nn.ReLU(True))
        self.class_classifier.add_module('c_drop1', nn.Dropout())
        self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))
        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(100))
        self.class_classifier.add_module('c_relu2', nn.ReLU(True))
        self.class_classifier.add_module('c_fc3', nn.Linear(100, 10))
        self.class_classifier.add_module('c_softmax', nn.LogSoftmax())

        self.domain_classifier = nn.Sequential()
        self.domain_classifier.add_module('d_fc1', nn.Linear(50 * 4 * 4, 100))
        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))
        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))
        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))
        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))

    def forward(self, input_data, alpha):
        input_data = input_data.expand(input_data.data.shape[0], 3, 28, 28)
        feature = self.feature(input_data)
        feature = feature.view(-1, 50 * 4 * 4)
        reverse_feature = ReverseLayerF.apply(feature, alpha)
        class_output = self.class_classifier(feature)
        domain_output = self.domain_classifier(reverse_feature)

        return class_output, domain_output

def infer(input_dir, output_dir, model_path, val_name):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"device: {device}")

    if val_name == "svhn":
        val_transform = transforms.Compose([
            transforms.Resize(28),
    #         transforms.Grayscale(num_output_channels=1),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.4414, 0.4459, 0.4716], std=[0.1960, 0.2000, 0.1976])
        ])
    elif val_name == "usps":
        val_transform = transforms.Compose([
            transforms.Resize(28),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.2574, 0.2574, 0.2574], std=[0.3524, 0.3524, 0.3524])
        ])
    else:
        print("Wrong val_name")
    val_dataset = DigitDataset(data_dir= input_dir, split="all", transform=val_transform)
    val_dataloader = DataLoader(val_dataset, shuffle=False)
    model = DANN().to(device)
    model = torch.load(model_path, device)
    model = model.eval()


    image_names = []
    preds = []
    for valid_image, filenames in val_dataloader:
        valid_image = valid_image.to(device)
        class_output, _ = model(input_data=valid_image, alpha=0)
        pred = class_output.data.max(1, keepdim=True)[1]
        pred = pred.cpu().numpy()
        image_names.append(filenames[0].split("/")[-1])
        preds.extend(pred[:, 0])
    df = pd.DataFrame(
        { 'image_name': image_names, 'label': preds})
    
    directory = os.path.dirname(output_dir)
    if not os.path.exists(directory):
        os.makedirs(directory)
    df.to_csv(output_dir, index=False)



if __name__ == "__main__":
    args = get_args()
    if "svhn" in args.input_dir:
        infer(args.input_dir, args.output_dir, args.svhn_model, val_name = "svhn")
    elif "usps" in args.input_dir:
        infer(args.input_dir, args.output_dir, args.usps_model, val_name = "usps")